{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cf279bd-5e63-4d95-818c-283e6619ccde",
   "metadata": {
    "tags": []
   },
   "source": [
    "## BGG Game Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18216e7-5126-4a49-84d8-1e256004d210",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d38c5480-8be1-486d-b83d-c302a166024c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from IPython.display import Image, display, Markdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7e6402-aecb-4a4b-858e-edd2d43ce81d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21d2446e-60f1-4334-90d8-c1c42487780e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to show the dimensions, column zero counts, column datatypes, column null counts, and the first and last 5 rows of the input dataframe\n",
    "\n",
    "# Function to return a dataframe with rows filtered by a specified word in a specified column:\n",
    "def df_keyword_search(df, column, word):\n",
    "    # Ensure the column is treated as strings and handle NaN values by replacing them with empty strings\n",
    "    column_data = df[column].fillna('').astype(str)\n",
    "    \n",
    "    # Filter the DataFrame based on the presence of the word in the specified column, case insensitive\n",
    "    keyword_df = df.loc[column_data.str.contains(rf'\\b{word}\\b', case=False, regex=True)]\n",
    "    \n",
    "    return keyword_df\n",
    "\n",
    "# Function that converts a string to lowercase, and replaces whitespace with underscores, unless the whitespace is adjacent to ' // '\n",
    "def format_text(words):\n",
    "    # converts the string to lowercase\n",
    "    result = str(words).lower()\n",
    "\n",
    "    # replaces whitespace with underscores, unless the whitespace is adjacent to ' // '\n",
    "    return(re.sub(r'(?<!//)\\s(?!//)', '_',result))\n",
    "\n",
    "# Function to replace '//' with ''\n",
    "def remove_double_slashes(text):\n",
    "    return text.replace(' // ', ' ')\n",
    "\n",
    "# Function to count the different words\n",
    "def count_words(df, column):\n",
    "    # Ensure the column is treated as strings, handling NaN values\n",
    "    column = df[column].fillna('').astype(str)\n",
    "    \n",
    "    # Concatenate all values in the column into a single string with '//' as a separator\n",
    "    all_words_sep = column.str.cat(sep='//')\n",
    "    \n",
    "    # Split the single string into words based on the separator\n",
    "    all_words = all_words_sep.split('//')\n",
    "    \n",
    "    # Convert the list of words into a pandas Series\n",
    "    words_series = pd.Series(all_words)\n",
    "    \n",
    "    # Count occurrences of each word and return the result\n",
    "    word_counts = words_series.value_counts()\n",
    "\n",
    "    # Convert the Series to a DataFrame with words and their counts\n",
    "    word_counts_df = word_counts.reset_index()\n",
    "    word_counts_df.columns = ['Word', 'Count']\n",
    "\n",
    "    # Calculate the percentage of total counts\n",
    "    total_count = word_counts_df['Count'].sum()\n",
    "    word_counts_df['Percentage'] = round((word_counts_df['Count'] / total_count) * 100,2)\n",
    "    \n",
    "    return word_counts_df\n",
    "\n",
    "# Function to find all games in a dataframe which contain a term, and then take the average of the numerical values of a selected column for all returned games\n",
    "def search_and_average(df, search_column, search_term, avg_column):\n",
    "    # Filter the rows where the search term is found in the search column\n",
    "    filtered_df = df[df[search_column].astype(str).str.contains(search_term, case=False, na=False)]\n",
    "    \n",
    "    # Exclude rows where the avg_column contains zero\n",
    "    filtered_df = filtered_df[filtered_df[avg_column] != 0]\n",
    "    \n",
    "    # Calculate the average of the second column for the filtered rows\n",
    "    avg_value = filtered_df[avg_column].mean()\n",
    "    \n",
    "    return avg_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb17488c-3658-449b-a988-34911d3a4c4e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Loading BGG ranked games data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0dd1d96b-7205-4924-adcf-2a1f59e85e33",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating dataframe from BGG_games_ranked.csv data\n",
    "rank_df = pd.read_csv('BGG_games_ranked.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d601d48-35d2-4085-aefe-6d0e5fb45d17",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ca10743-5f73-44ad-8f7c-d77a74945db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>yearpublished</th>\n",
       "      <th>rank</th>\n",
       "      <th>bayesaverage</th>\n",
       "      <th>average</th>\n",
       "      <th>usersrated</th>\n",
       "      <th>is_expansion</th>\n",
       "      <th>abstracts_rank</th>\n",
       "      <th>cgs_rank</th>\n",
       "      <th>childrensgames_rank</th>\n",
       "      <th>familygames_rank</th>\n",
       "      <th>partygames_rank</th>\n",
       "      <th>strategygames_rank</th>\n",
       "      <th>thematic_rank</th>\n",
       "      <th>wargames_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>224517</td>\n",
       "      <td>brass: birmingham</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>8.41509</td>\n",
       "      <td>8.59780</td>\n",
       "      <td>45924</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161936</td>\n",
       "      <td>pandemic legacy: season 1</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>8.37995</td>\n",
       "      <td>8.52747</td>\n",
       "      <td>53515</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>174430</td>\n",
       "      <td>gloomhaven</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>8.35320</td>\n",
       "      <td>8.58904</td>\n",
       "      <td>62182</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>342942</td>\n",
       "      <td>ark nova</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>8.33425</td>\n",
       "      <td>8.53493</td>\n",
       "      <td>43527</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>233078</td>\n",
       "      <td>twilight imperium: fourth edition</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>8.24195</td>\n",
       "      <td>8.60175</td>\n",
       "      <td>23816</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                               name  yearpublished  rank  \\\n",
       "0  224517                  brass: birmingham           2018     1   \n",
       "1  161936          pandemic legacy: season 1           2015     2   \n",
       "2  174430                         gloomhaven           2017     3   \n",
       "3  342942                           ark nova           2021     4   \n",
       "4  233078  twilight imperium: fourth edition           2017     5   \n",
       "\n",
       "   bayesaverage  average  usersrated  is_expansion  abstracts_rank  cgs_rank  \\\n",
       "0       8.41509  8.59780       45924             0             NaN       NaN   \n",
       "1       8.37995  8.52747       53515             0             NaN       NaN   \n",
       "2       8.35320  8.58904       62182             0             NaN       NaN   \n",
       "3       8.33425  8.53493       43527             0             NaN       NaN   \n",
       "4       8.24195  8.60175       23816             0             NaN       NaN   \n",
       "\n",
       "   childrensgames_rank  familygames_rank  partygames_rank  strategygames_rank  \\\n",
       "0                  NaN               NaN              NaN                 1.0   \n",
       "1                  NaN               NaN              NaN                 2.0   \n",
       "2                  NaN               NaN              NaN                 4.0   \n",
       "3                  NaN               NaN              NaN                 3.0   \n",
       "4                  NaN               NaN              NaN                 5.0   \n",
       "\n",
       "   thematic_rank  wargames_rank  \n",
       "0            NaN            NaN  \n",
       "1            1.0            NaN  \n",
       "2            2.0            NaN  \n",
       "3            NaN            NaN  \n",
       "4            3.0            NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing each string element of the dataframe to lower case to support with EDA\n",
    "rank_df = rank_df.map(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "\n",
    "# Checking changes have been made\n",
    "rank_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358f4bae-4957-41db-96b6-428fe2b86972",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Defining selection of Games to download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623ceb6d-6e7f-4d87-9fac-a4112ec6caf1",
   "metadata": {},
   "source": [
    "#### Filtering dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d8b8bca-694e-4701-a617-c6c76494998c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['name_prefix', 'name_prefix_count'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 13\u001b[0m\n\u001b[0;32m      2\u001b[0m features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname_prefix\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124musersrated\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_expansion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Filtering the ID's of board games to consider when retrieving data from each board game API\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m rank_df_filtered \u001b[38;5;241m=\u001b[39m rank_df\u001b[38;5;241m.\u001b[39mloc[(rank_df\u001b[38;5;241m.\u001b[39maverage \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;66;03m# include games with an average rating of 7 or above\u001b[39;00m\n\u001b[0;32m     14\u001b[0m                                (rank_df\u001b[38;5;241m.\u001b[39musersrated \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;66;03m# include games with at least 100 ratings\u001b[39;00m\n\u001b[0;32m     15\u001b[0m                                (rank_df\u001b[38;5;241m.\u001b[39mis_expansion \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;66;03m# exclude game expansions, just include base games\u001b[39;00m\n\u001b[0;32m     16\u001b[0m                                features]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1147\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1150\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1339\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[0;32m   1337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take(tup)\n\u001b[1;32m-> 1339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:994\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_null_slice(key):\n\u001b[0;32m    992\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 994\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(retval, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\u001b[38;5;241m.\u001b[39m_getitem_axis(key, axis\u001b[38;5;241m=\u001b[39mi)\n\u001b[0;32m    995\u001b[0m \u001b[38;5;66;03m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[0;32m    996\u001b[0m \u001b[38;5;66;03m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[0;32m    997\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m retval\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1382\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1380\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_iterable(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1322\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_listlike_indexer(key, axis)\n\u001b[0;32m   1323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1324\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1325\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1520\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1517\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1518\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1520\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, axis_name)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6115\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6113\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6117\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6119\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6179\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6178\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6179\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['name_prefix', 'name_prefix_count'] not in index\""
     ]
    }
   ],
   "source": [
    "# Features from the rank_df to retain\n",
    "features = ['id',\n",
    "            'name',\n",
    "            'name_prefix',\n",
    "            'name_prefix_count',\n",
    "            'yearpublished',\n",
    "            'average',\n",
    "            'bayesaverage',\n",
    "            'usersrated',\n",
    "            'is_expansion']\n",
    "\n",
    "# Filtering the ID's of board games to consider when retrieving data from each board game API\n",
    "rank_df_filtered = rank_df.loc[(rank_df.average >= 7) & # include games with an average rating of 7 or above\n",
    "                               (rank_df.usersrated >= 100) & # include games with at least 100 ratings\n",
    "                               (rank_df.is_expansion == 0), # exclude game expansions, just include base games\n",
    "                               features].reset_index(drop=True).copy() # resets current index & creates a copy of the DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e064fc2c-e836-4370-b5b5-3814b129d0eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checking the contents and reduction in the size of the filtered DF:\n",
    "check_df(rank_df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d728a5-7ba0-4fc6-bf10-d787cb691351",
   "metadata": {},
   "source": [
    "#### Adding new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d728f9a-0b80-4d8f-804f-4942440394c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Columns to include in rank_df_filtered\n",
    "columns = ('id',\n",
    "           'name',\n",
    "           'name_prefix',\n",
    "           'name_prefix_count',\n",
    "           'yearpublished',\n",
    "           'average',\n",
    "           'usersrated',\n",
    "           'number of comments',\n",
    "           'complexity votes',\n",
    "           'average complexity',\n",
    "           'year published',\n",
    "           'min player number',\n",
    "           'max player number',\n",
    "           'min play time',\n",
    "           'max play time',\n",
    "           'expected play time',\n",
    "           'minimum age limit',\n",
    "           'category',\n",
    "           'mechanism',\n",
    "           'game designer',\n",
    "           'publisher',\n",
    "            'url')\n",
    "\n",
    "# Iterating through columns and checks if it is present in rank_df_filtered, \n",
    "# if not then if adds the column, with each row filled with empty string values\n",
    "for col in columns:\n",
    "    if col not in rank_df_filtered.columns:\n",
    "        rank_df_filtered[col] = ''\n",
    "\n",
    "# Remove any unwanted columns\n",
    "for col in rank_df_filtered.columns:\n",
    "    if col not in columns:\n",
    "        rank_df_filtered.drop([col], axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b89b2e0-29cd-43af-a503-04f177d1d9cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checking new size of rank_df_filtered and if new columns have been added:\n",
    "check_df(rank_df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c1999e-20c2-437b-b21b-162aceae55e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Cleaning filtered dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae071e8-9220-4123-a44d-527a1f4efd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all \"games\" with the name accessory or accessories included\n",
    "rank_df_filtered.drop(rank_df_filtered[rank_df_filtered.name.str.contains('accessory',case = False)].index,inplace=True)\n",
    "rank_df_filtered.drop(rank_df_filtered[rank_df_filtered.name.str.contains('accessories',case = False)].index,inplace=True)\n",
    "rank_df_filtered['id'].count() # Count the number of reduced rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d8085d-77ae-417d-9652-ba9cc0e154e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all \"games\" with the name expansion included\n",
    "rank_df_filtered.drop(rank_df_filtered[rank_df_filtered.name.str.contains('expansion',case = False)].index,inplace=True)\n",
    "rank_df_filtered['id'].count() # Count the number of reduced rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b3fa9e-0c80-44cb-8868-cca408da09ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting all the rows by name prefix then year published to show the first instances of the game at the top of the sub section for the name prefix\n",
    "rank_df_filtered.sort_values(by = ['name_prefix_count','name_prefix','yearpublished'],ascending = [False,True,True]).\\\n",
    "            drop_duplicates(subset='name_prefix', keep='first').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a546d7d-aae9-4e18-a3e2-8ef812502d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of game id's to remove from the dataframe, focusing on expansions or editions that are not the base game\n",
    "\n",
    "remove_lst=[]\n",
    "remove_lst =  rank_df_filtered.loc[rank_df_filtered['name_prefix']=='magic','id'].iloc[1:].tolist()\n",
    "#remove_lst.extend(rank_df_filtered.loc[rank_df_filtered['name_prefix']=='pokemon tcg','id'].iloc[1:].tolist())\n",
    "\n",
    "# Showing the id's to be removed\n",
    "remove_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fd8981-9e13-4760-a9c1-c937b99c45e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the id's based on the remove_lst from above\n",
    "rank_df_filtered = rank_df_filtered[~rank_df_filtered['id'].isin(remove_lst)]\n",
    "\n",
    "# Checking the games intended to be removed are actually removed\n",
    "rank_df_filtered[rank_df_filtered['id'].isin(remove_lst)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c3daef-ce1e-44ae-a817-037ccb4a2ed7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pulling data from BGG Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f4e5d3-c83c-47fc-a3ed-561815147c02",
   "metadata": {},
   "source": [
    "#### Testing data retrieval through BGG API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d16d88-43f5-42a0-9a76-492b44360f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checking the output of data retrieved for a specifc board game using the BGG API\n",
    "\n",
    "test_id = 224517 # Variable specifying a single board game id\n",
    "link_temp = f'https://boardgamegeek.com/xmlapi2/thing?id={test_id}&type=boardgame&versions=1&stats=1&marketplace=1&ratingcomments=1' # This is the template URL for the API request, accesses data for the specific game id ('test_id')\n",
    "\n",
    "response = requests.get(link_temp) # Sending request and returning a repsonse object from the BGG server (XML data)\n",
    "root = ET.fromstring(response.content)  # Parse XML into tree structure\n",
    "\n",
    "print(link_temp) # URL for API request sent\n",
    "\n",
    "# Printing game characteristics from the server response for the specified game:\n",
    "print(f'Title: ',root.find('.//name[@type=\"primary\"]').get('value')) # Primary name of the game\n",
    "print(f'Number of comments from users: ',root.find('.//numcomments').get('value')) # Number of comments sent as part of ratings\n",
    "print(f'Year published: ',root.find('.//yearpublished').get('value')) # Year the game was published\n",
    "print(f'Min number of players:',root.find('.//minplayers').get('value')) # Minimum number of players\n",
    "print(f'Max number of players: ',root.find('.//maxplayers').get('value')) # Maximum number of players\n",
    "print(f'Expected playtime: ',root.find('.//playingtime').get('value')) # Expected playtime\n",
    "print(f'Min playtime: ',root.find('.//minplaytime').get('value')) # Minimum playtime\n",
    "print(f'Max playtime: ',root.find('.//maxplaytime').get('value')) # Maximum playtime\n",
    "print(f'Min playing age: ',root.find('.//minage').get('value')) # Minimum playing age\n",
    "print(f'Number of votes on game complexity: ',root.find('.//numweights').get('value')) # Number of user votes on game complexity\n",
    "print(f'Average rating of complexity (0=low & 5=high): ',root.find('.//averageweight').get('value')) # Average game complexity rating, 0 = low & 5 = high\n",
    "\n",
    "# Creating sets for game characteristics with mutliple elements:\n",
    "test_categories = set() # Contains all associated categories\n",
    "test_mechanics = set() # Contains all associated mechanics\n",
    "test_families = set() # Contains all associated families\n",
    "test_designers = set() # Contains all associated designers\n",
    "test_publishers = set() # Contains all associated publishers\n",
    "\n",
    "# Collecting data from the server response and adding entries to each set:\n",
    "for link in root.findall('.//link[@type=\"boardgamecategory\"]'): # Categories\n",
    "    test_categories.add(link.get('value'))\n",
    "    \n",
    "for link in root.findall('.//link[@type=\"boardgamemechanic\"]'): # Mechanics\n",
    "    test_mechanics.add(link.get('value'))\n",
    "    \n",
    "for link in root.findall('.//link[@type=\"boardgamedesigner\"]'): # Designers\n",
    "    test_designers.add(link.get('value'))\n",
    "    \n",
    "for link in root.findall('.//versions/item/link[@type=\"boardgamepublisher\"]'): # Publishers\n",
    "    test_publishers.add(link.get('value'))\n",
    "\n",
    "# Printing game characteristics with multiple elements:\n",
    "print(f'Categories: ',test_categories) # Categories associated with the game\n",
    "print(f'Mechanics: ',test_mechanics) # Mechanics associated with the game\n",
    "print(f'Designers: ',test_designers) # Game designers involved\n",
    "print(f'Publishers: ',test_publishers) # Game publishers involved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ffb5a-a97d-494f-827a-86d98474752a",
   "metadata": {},
   "source": [
    "#### Full data retrieval through BGG API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9ca876c9-fc20-4827-852c-b7c7abedc1b0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 220308 - Progress = 12 / 4981 - Timestamp: 16-09 09:09:35"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 57\u001b[0m\n\u001b[0;32m     55\u001b[0m id_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(rank_df_filtered) \u001b[38;5;66;03m# Total number of game id's that will iterated through for each server request\u001b[39;00m\n\u001b[0;32m     56\u001b[0m start\u001b[38;5;241m=\u001b[39mstart\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# Off-setting the start count by 1 to show the 1st server request as the number 1 not 0\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# Adding a delay of 5 seconds before retrying the server request for the next game\u001b[39;00m\n\u001b[0;32m     58\u001b[0m current_timestamp \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m#  # Get the current date and time and format it as \"day-month hour:minute:second\"\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124mid \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mid\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Progress = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mid_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Timestamp: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_timestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# Printing the current progress of data extraction, including: the current game ID, progress count, and timestamp\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Collecting data on each game specified in the rank_df_filtered table:\n",
    "\n",
    "start = 0 # Index value in rank_df_filtered corresponding to the game id you want to start pulling data for, 0 if starting anew\n",
    "\n",
    "# Looping through each row index of rank_df_filtered from a defined 'start' variable to the last row\n",
    "for i in range(start,len(rank_df_filtered)):\n",
    "   \n",
    "    id = rank_df_filtered.loc[i,'id'] # Assigning the variable 'id' with the 'game id' from the current index iteration, this used to select the page of information for a specific game to request from the server\n",
    "    \n",
    "    try:\n",
    "        url = f'https://boardgamegeek.com/xmlapi2/thing?id={id}&type=boardgame&versions=1&stats=1&marketplace=1&ratingcomments=1' # This is the template URL for the API request, accesses data for the specific game 'id'\n",
    "        response = requests.get(url) # Sending request and returning a repsonse object from the BGG server (XML data)\n",
    "        root = ET.fromstring(response.content)  # Parse XML into tree structure\n",
    "        \n",
    "        # Creating sets for game characteristics with mutliple elements:\n",
    "        categories = set()\n",
    "        mechanic = set()\n",
    "        family = set()\n",
    "        designer = set()\n",
    "        publisher = set()\n",
    "        \n",
    "        # Updating rank_df_filtered fields with game characteristics from the server response (single elements):\n",
    "        rank_df_filtered.at[i, 'number of comments'] = root.find('.//numcomments').get('value') # Number of comments\n",
    "        rank_df_filtered.at[i, 'complexity votes'] = root.find('.//numweights').get('value') # Number of complexity votes\n",
    "        rank_df_filtered.at[i, 'average complexity'] = root.find('.//averageweight').get('value') # Average complexity rating\n",
    "        rank_df_filtered.at[i, 'year published'] = root.find('.//yearpublished').get('value') # Year published\n",
    "        rank_df_filtered.at[i, 'min player number'] = root.find('.//minplayers').get('value') # Minimum number of players\n",
    "        rank_df_filtered.at[i, 'max player number'] = root.find('.//maxplayers').get('value') # Maximum number of players\n",
    "        rank_df_filtered.at[i, 'expected play time'] = root.find('.//playingtime').get('value') # Expected playtime\n",
    "        rank_df_filtered.at[i, 'min play time'] = root.find('.//minplaytime').get('value') # Minimum play time\n",
    "        rank_df_filtered.at[i, 'max play time'] = root.find('.//maxplaytime').get('value') # Maximum play time\n",
    "        rank_df_filtered.at[i, 'minimum age limit'] = root.find('.//minage').get('value') # Minimum age limit\n",
    "        \n",
    "\n",
    "        # Updating rank_df_filtered fields with game characteristics from the server response (multiple elements):\n",
    "        for link in root.findall('.//link[@type=\"boardgamecategory\"]'): # Categories\n",
    "            categories.add(link.get('value'))\n",
    "        for link in root.findall('.//link[@type=\"boardgamemechanic\"]'): # Mechanics\n",
    "            mechanic.add(link.get('value'))\n",
    "        for link in root.findall('.//link[@type=\"boardgamedesigner\"]'): # Designers\n",
    "            designer.add(link.get('value'))\n",
    "        for link in root.findall('.//link[@type=\"boardgamepublisher\"]'): # Publishers\n",
    "            publisher.add(link.get('value'))\n",
    "\n",
    "        # Convert set to a list with ' // ' separator:\n",
    "        rank_df_filtered.at[i, 'category'] = ' // '.join(categories) # Categories\n",
    "        rank_df_filtered.at[i, 'mechanism'] = ' // '.join(mechanic) # Mechanics\n",
    "        rank_df_filtered.at[i, 'game designer'] = ' // '.join(designer) # Designers\n",
    "        rank_df_filtered.at[i, 'publisher'] = ' // '.join(publisher) # Publishers\n",
    "\n",
    "        # Updating the rank_df_filtered URL field showing the URL used to access the BGG server for the specific game:\n",
    "        rank_df_filtered.at[i, 'url'] = url\n",
    "        \n",
    "        # Live status on progress of game data extraction from BGG server:\n",
    "        id_count = len(rank_df_filtered) # Total number of game id's that will iterated through for each server request\n",
    "        start=start+1 # Off-setting the start count by 1 to show the 1st server request as the number 1 not 0\n",
    "        time.sleep(5)  # Adding a delay of 5 seconds before retrying the server request for the next game\n",
    "        current_timestamp = datetime.now().strftime(\"%d-%m %H:%M:%S\") #  # Get the current date and time and format it as \"day-month hour:minute:second\"\n",
    "        print(f'\\rid {id} - Progress = {i+1} / {id_count} - Timestamp: {current_timestamp}', end='') # Printing the current progress of data extraction, including: the current game ID, progress count, and timestamp\n",
    "\n",
    "    \n",
    "    except AttributeError as e: # Exception handling for elements that do not exist\n",
    "        \n",
    "        print(f\"AttributeError for id {id}: {e}\") # printing the specific game id and error description\n",
    "        \n",
    "        continue  # Skip to the next iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0be5a04-a1a4-4501-be76-a4f682ffc790",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52dc6e5-11a0-440d-8854-e5a38c0c76ce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check contents of the newly added data to rank_df_filtered\n",
    "check_df(rank_df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b24a75a-7dcf-45bf-bedf-9e704f65ed3a",
   "metadata": {},
   "source": [
    "#### Saving the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bee6cfe-1f0a-45c8-abc2-4b8f411e6415",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saving the data to csv, left commented to ensure Games_filtered.csv is not overwritten in new session\n",
    "# rank_df_filtered.to_csv('Games_filtered.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
